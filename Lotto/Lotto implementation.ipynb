{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Lotto Implementation\n",
    "(based on the \"Open-ended Learning in Symmetric Zero-sum Games\" paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "\n",
    "**Differentiable Lotto** is inspired by continuous Lotto (Hart, S. Discrete Colonel Blotto and General Lotto games. Int J Game Theory, 36:441–460, 2008.). The game is defined over a fixed set $C$ of $c$ 'customers', each being a point in $\\mathbb{R}^2$. An agent’s strategy $(p, v) = \\{(p_1,v_1), ... , (p_k,v_k)\\}$, distributes one unit of mass over $k$ servers, where each server is a point $v_i \\in \\mathbb{R}^2$. Roughly, given the strategies of two players, $(p,v)$, $(q,w)$, customers are softly assigned to the nearest servers, determining the agents’ payoffs.\n",
    "\n",
    "More formally, the payoff is\n",
    "\n",
    "$$\n",
    "\\phi((p,v), (q,w)) := \\sum_{i,j=1}^{c,k} (p_j v_{ij} - q_j w_{ij}),$$\n",
    "\n",
    "where the scalars $v_{ij}$ and $w_{ij}$ depend on the distance between customer $i$ and the servers:\n",
    "\n",
    "$$(v_{i1}, ... , w_{ik}) := softmax(-||c_i - v_1||^2, ... , -||c_i - w_k||^2),$$\n",
    "\n",
    "where $c_i$ is the coordinate of customer $i$.\n",
    "\n",
    "The width of a cloud of points is the expected distance from the barycenter. We impose agents to have width equal one. We use gradient ascent as our oracle.\n",
    "\n",
    "For this implmentation,\n",
    "\n",
    "- $c = 9$ customers chosen uniformly at random in the square $[-1,1]^2$\n",
    "- $k = 2$ servers\n",
    "- $n = 500$ games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code Implementation of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initialization of initial strategies and fixed c customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*random_point(lb = -1, ub = 1, n = 2)*:\n",
    "- Input: Lower bound (lb), upper bound (ub) of each coordinate in $\\mathbb{R}^n$ space\n",
    "- Output: random point within the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point(lb = -1, ub = 1, n = 2):\n",
    "    point = np.zeros((n,))\n",
    "    for i in range(n):\n",
    "        point[i] = np.random.uniform(lb, ub)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36229518, 0.36394426])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*random_points_list(lb = -1, ub = 1, n = 2, k = 2)*:\n",
    "- Input: $k$ number of points with lower bound (lb), upper bound (ub) of each coordinate in $\\mathbb{R}^n$ space\n",
    "- Output: list of $k$ random points within the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_points_list(lb = -1, ub = 1, n = 2, k = 9):\n",
    "    points_list = []\n",
    "    for i in range(k):\n",
    "        points_list.append(random_point(lb,ub,n))\n",
    "    points_list = np.asarray(points_list)\n",
    "    return points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07289642,  0.89895292],\n",
       "       [-0.47312269,  0.08480472],\n",
       "       [ 0.09138947, -0.36477769],\n",
       "       [-0.09047958, -0.11435868],\n",
       "       [ 0.95584869,  0.56662997],\n",
       "       [-0.47810368, -0.0714073 ],\n",
       "       [-0.79524905,  0.42234337],\n",
       "       [ 0.53449333, -0.62198365],\n",
       "       [-0.99056606,  0.8104629 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_points_list(k=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*prob_dist(k = 2)*:\n",
    "- Input: $k$\n",
    "- Output: $k$ numbers that sum up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_dist(k = 2):\n",
    "    pd = np.random.uniform(0,1,k)\n",
    "    total = np.sum(pd)\n",
    "    pd = pd/total\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44830956, 0.55169044])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialise_strategy(lb = -1, ub = 1, n = 2, k = 2)*:\n",
    "- Input: $k$ number of points with lower bound (lb), upper bound (ub) of each coordinate in $\\mathbb{R}^n$ space\n",
    "- Output: p_vector (distribution of k points) and v_vector (k points in $\\mathbb{R}^n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_strategy(lb = -1, ub = 1, n = 2, k = 2):\n",
    "    v_vector = random_points_list(lb, ub, n, k)\n",
    "    p_vector = prob_dist(k)\n",
    "    return p_vector, v_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.40571654, 0.59428346]), array([[ 0.42913459, -0.56027163],\n",
       "        [ 0.79665451, -0.23165189]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialise_strategy(lb = -1, ub = 1, n = 2, k = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take for example: Generate 2 players' strategies: (p,v) and (q,w) with k = 2 servers each. c = 9 Customers in $[-1,1]^2$ space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player's strategies distribution: [0.7109327 0.2890673] with servers at [[ 0.52377423 -0.13829908]\n",
      " [-0.64764852  0.00605504]].\n",
      "The customers are located at [[-0.40930006 -0.11372282]\n",
      " [ 0.45471504 -0.40404271]\n",
      " [-0.19604131  0.21068581]\n",
      " [ 0.51727535 -0.21181064]\n",
      " [-0.89968634  0.06983997]\n",
      " [ 0.69187852 -0.18296335]\n",
      " [-0.61434465 -0.82354691]\n",
      " [ 0.40273431 -0.44720276]\n",
      " [-0.97642773 -0.3457468 ]].\n"
     ]
    }
   ],
   "source": [
    "lb = -1 #lower bound of the space\n",
    "ub = 1 #upper bound of the space\n",
    "n = 2 #dimension of the space\n",
    "k = 2 #number of servers\n",
    "c = 9 #number of customers\n",
    "\n",
    "p,v = initialise_strategy(lb, ub, n, k)\n",
    "C = random_points_list(lb, ub, n, k = c)\n",
    "print(\"Player's strategies distribution: \" + np.array2string(p) + \" with servers at \" + np.array2string(v) + \".\")\n",
    "print(\"The customers are located at \" + np.array2string(C) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Necessary functions for PSRO algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nash_eq(A)*:\n",
    "- Input: matrix A of a population\n",
    "- Output: Nash equilibrium p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nash_eq(A):\n",
    "    '''Input: matrix A of a population\n",
    "       Output: Nash equilibrium\n",
    "       Note that A need to be antisymmetric for this function to generate the right Nash p'''\n",
    "    n = A.shape[0]\n",
    "    A_ub = np.concatenate((-A.T,[np.ones(n,),-np.ones(n,)]), axis = 0)\n",
    "    b_ub = np.append(np.zeros((n,)),[1,-1])\n",
    "    soln = linprog(c = np.zeros((n,)), A_ub = A_ub, b_ub = b_ub, bounds = (0,1))\n",
    "    return soln.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPS example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,1,-1],[-1,0,1],[1,-1,0]])\n",
    "print(Nash_eq(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eval_matrix_1pop(popn)*:\n",
    "- Input: list of strategies from 1 population of strategies where each strategy = $[p^i,v^i]$\n",
    "- Output: evaluation matrix A (as described in Section 2 of the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_matrix_1pop(popn):\n",
    "    '''Input: 1 population of strategies\n",
    "       Output: evaluation matrix of that population'''\n",
    "    n = len(popn)\n",
    "    matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            matrix[i][j] = payoff(popn[i],popn[j])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eval_matrix_2pop(popn)*:\n",
    "- Input: lists of strategies from 2 population of strategies where each strategy = $[p^i,v^i]$ (no. of strategies from population A can differ from population B's)\n",
    "- Output: evaluation matrix A (as described in Section 2 of the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_matrix_2pop(popn1,popn2):\n",
    "    '''Input: 2 population of strategies\n",
    "       Output: evaluation matrix of those 2 populations'''\n",
    "    n = len(popn1)\n",
    "    m = len(popn2)\n",
    "    matrix = np.zeros((n,m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            matrix[i][j] = payoff(popn1[i],popn2[j])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 PSRO$_N$ Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSRO_N(popn, epoch = 100):\n",
    "    strategies = popn\n",
    "    n = len(strategies)\n",
    "    for i in range(epoch):\n",
    "        A = eval_matrix(strategies)\n",
    "        nash_p = Nash_eq(A)\n",
    "        new_strategy = oracle(nash_p, strategies)\n",
    "        strategies.append(new_strategy)\n",
    "        n = n + 1\n",
    "        print(\"There are \" + n + \" strategies in the population now.\")\n",
    "    return strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Population Performance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rel_popn_perf(popn1, popn2)*:\n",
    "- Input: lists of strategies from 2 population of strategies where each strategy = $[p^i,v^i]$ (no. of strategies from population A can differ from population B's)\n",
    "- Output: relative population performance (defined in Definition 3 of Section 3.1 in th paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_popn_perf(popn1, popn2):\n",
    "    perf = 0\n",
    "    A_1 = eval_matrix_1pop(popn1)\n",
    "    A_2 = eval_matrix_1pop(popn2)\n",
    "    A_12 = eval_matrix_2pop(popn1,popn2)\n",
    "    p = Nash_eq(A_1).reshape(-1,1)\n",
    "    q = Nash_eq(A_2).reshape(-1,1)\n",
    "    perf = np.dot(np.dot(p.T,A_12),q)\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eff_diversity(popn)*:\n",
    "- Input: list of strategies from 1 population of strategies where each strategy = $[p^i,v^i]$\n",
    "- Output: effective diversity of the population (defined in Definition 4 of Section 3.2 in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_diversity(popn):\n",
    "    d = 0\n",
    "    A = eval_matrix_1pop(popn)\n",
    "    p = Nash_eq(A).reshape(-1,1)\n",
    "    A_plus = np.clip(A,0,None)\n",
    "    d = np.dot(np.dot(p.T,A_plus),p)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_fn(v,w,C,k,c):\n",
    "    dist_v=np.zeros((c,k));\n",
    "    dist_w=np.zeros((c,k));\n",
    "    soft_v=np.zeros((c,k));\n",
    "    soft_w=np.zeros((c,k));\n",
    "    for i in range(c):\n",
    "        for j in range(k):\n",
    "            dist_v[i][j]=np.exp(-np.norm(C[i,:]-v[j,:]))\n",
    "            dist_w[i][j]=np.exp(-np.norm(C[i,:]-w[j,:]))\n",
    "        soft_v[i,:]=dist_v[i,:]/(np.sum(dist_v[i,:])+np.sum(dist_w[i,:]));\n",
    "        soft_w[i,:]=dist_w[i,:]/(np.sum(dist_v[i,:])+np.sum(dist_w[i,:]));\n",
    "    return soft_v,soft_w,dist_v,dist_w     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff(p,soft_v,q,soft_w):\n",
    "    payoff=np.sum(np.dot(soft_v,p)-np.dot(soft_w,q))\n",
    "    return payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(popn,nash_p,eta,C,k,c):\n",
    "    curr_agent_p=popn[-1][0];\n",
    "    curr_agent_v=popn[-1][1];\n",
    "    next_agent_p=curr_agent_p+eta*gradient_p(popn,nash_p,curr_agent_v,C,k,c);\n",
    "    next_agent_v=curr_agent_v+eta*gradient_v(popn,nash_p,curr_agent_p,curr_agent_v,C,k,c);\n",
    "    return next_agent_p,next_agent_v;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_p(popn,nash_p,agent_v,C,k,c):\n",
    "    sum_vec=np.zeros((k,1));\n",
    "    for i in range(len(popn)):\n",
    "        temp_agent_p=popn[i][0];\n",
    "        temp_agent_p=popn[i][1];\n",
    "        temp_v,temp_w,tempdist_v,tempdist_w=softmax_fn(agent_v,temp_agent_w,C,k,c);\n",
    "        val_grad=np.sum(temp_v,axis=0) #sum the rows\n",
    "        sum_vec=sum_vec+nash_p[i]*val_grad; #multiply w.r.t Nash p.\n",
    "        \n",
    "    return sum_vec;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_v(popn,nash_p,agent_p,agent_v,C,k,c): #agent_p, agent_v are strategies of the current agent \"v_t of popn B_t\"\n",
    "    sum_mat=np.zeros((k,2));\n",
    "    for i in range(len(popn)):\n",
    "        temp_agent_p=popn[i][0];\n",
    "        temp_agent_v=popn[i][1];\n",
    "        temp_v,temp_w,tempdist_v,tempdist_w=softmax_fn(agent_v,temp_agent_v,C,k,c);\n",
    "        val_grad_mat=calc_gradient_matrix(agent_p,agent_v,temp_agent_p,temp_agent_v,temp_v,temp_w,tempdist_v,tempdist_w,C,k,c) #sum the rows\n",
    "        #To add the remaining parameters to calc_gradient_matrix function-See below.\n",
    "        sum_mat=sum_mat+nash_p[i]*val_grad_mat; #multiply w.r.t Nash p.\n",
    "        \n",
    "    return sum_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_matrix(agent_p,agent_v,temp_agent_p,temp_agent_v,temp_v,temp_w,tempdist_v,tempdist_w,C,k,c):\n",
    "    #agent_p - p vector of agent v_t\n",
    "    #temp_agent_q- q vector of the \"current opposition agent\"\n",
    "    #W- location matrix of \"current opposition agent\"\n",
    "    #V- location matrix of agent v_t\n",
    "    grad_mat=np.zeros((k,2));\n",
    "    V=agent_v;\n",
    "    W=temp_agent_v;\n",
    "    for j in range(k):\n",
    "      S_v=0;\n",
    "      S_w=0;\n",
    "      for i in range(c):\n",
    "        for l in range(k):\n",
    "            v_loc=V[j,:];\n",
    "            S_v=S_v+agent_p[j]*grad_payoff(v_loc,j,l,1,i,temp_v,temp_w,dist_v,dist_w,C,k,c);\n",
    "            S_w=S_w+temp_agent_p[j]*grad_payoff(v_loc,j,l,0,i,temp_v,temp_w,dist_v,dist_w,C,k,c);\n",
    "        \n",
    "         \n",
    "      grad_mat[j,:]=S_v-S_w;  \n",
    "      \n",
    "    return grad_mat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_payoff(v_loc,v_loc_idx,w_loc_idx,agent_bool,c_idx,temp_v,temp_w,dist_v,dist_w,C,k,c): #Gradient with respect to v_loc a location strategy of agent v.\n",
    "    \n",
    "    if(agent_bool==1): #Differentiating agent_v\n",
    "        \n",
    "     if(v_loc_idx~=w_loc_idx):\n",
    "         grad=(2*(C[c_idx,:]-v_loc)*dist_v(c_idx,v_loc_idx)*(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:])-dist_v(c_idx,v_loc_idx)))/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))^2\n",
    "     else:\n",
    "        grad=(-2*(C[c_idx,:]-v_loc)*dist_v(c_idx,v_loc_idx)*dist_v(c_idx,w_loc_idx))/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))^2\n",
    "    \n",
    "    else:\n",
    "        \n",
    "     if(v_loc_idx~=w_loc_idx): #Differentiating agent_w\n",
    "         grad=(2*(C[c_idx,:]-v_loc)*dist_v(c_idx,v_loc_idx)*(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:])-dist_w(c_idx,v_loc_idx)))/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))^2\n",
    "     else:\n",
    "         grad=(-2*(C[c_idx,:]-v_loc)*dist_v(c_idx,v_loc_idx)*dist_w(c_idx,w_loc_idx))/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))^2   \n",
    "    \n",
    "    return grad    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
