{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colonel Blotto Implementation\n",
    "(based on the \"Open-ended Learning in Symmetric Zero-sum Games\" paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "**Colonel Blotto** is a resource allocation game that is often used as a model for electoral competition. Each of two players has a budget of $c$ coins which they simultaneously distribute over a fixed number of areas. Area $a_i$ is won by the player with more coins on $a_i$. The player that wins the most areas wins the game. Since Blotto is not differentiable, maximum a posteriory policy optimization (MPO) (\"Maximum a Posteriori Policy Optimisation\", Abdolmaleki et al., 2018) is used as best response oracle. MPO is an inference-based policy optimization algorithm; many other reinforcement learning algorithms could be used.\n",
    "\n",
    "For this implmentation,\n",
    "\n",
    "- $c = 10$\n",
    "- $i = 3$\n",
    "- $k = 1000$ games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code Implementation of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*blotto(A,B)*: Play a single colonel blotto battle between strategy A and B\n",
    "\n",
    "- *Input:* strategy A and B (each strategy is a vector of 3 numbers that add up to 10)\n",
    "- *Output:* \n",
    "\n",
    "    - 1 if A wins\n",
    "    - -1 if B wins\n",
    "    - 0 if tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blotto(A,B):\n",
    "    \"\"\"execute a colonel blotto battle between A & B players. Note that both A and B are lists of numbers.\"\"\"\n",
    "    #to check if the length of both players are the same\n",
    "    if(len(A) != len(B)):\n",
    "       print('fronts mismatch')\n",
    "       return\n",
    "    \n",
    "    battles = [0,0]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        if A[i] > B[i]: battles[0] += 1\n",
    "        if A[i] < B[i]: battles[1] += 1\n",
    "\n",
    "    if battles[0] > battles[1]: \n",
    "        return 1\n",
    "    if battles[0] < battles[1]: \n",
    "        return -1\n",
    "    if battles[0] == battles[1]: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*payoff_matrices(A_strategies, B_strategies)*:\n",
    "\n",
    "*Input*: a set of strategies from A and a set from B\n",
    "\n",
    "*Output*: payoff matrices for A and B based on different combination of strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff_matrices(A_strategies, B_strategies):\n",
    "    '''Generate individual payoff matrix for both A and B based on different combination of strategies.'''\n",
    "    nA = len(A_strategies)\n",
    "    nB = len(B_strategies)\n",
    "    matrixA = numpy.zeros((nA,nB))\n",
    "    matrixB_temp = numpy.zeros((nA,nB))\n",
    "    for i in range(nA):\n",
    "        for j in range(nB):\n",
    "            if blotto(A_strategies[i],B_strategies[j]) == 1:\n",
    "                matrixA[i][j] = 1\n",
    "                matrixB_temp[i][j] = -1\n",
    "            elif blotto(A_strategies[i],B_strategies[j]) == -1:\n",
    "                matrixA[i][j] = -1\n",
    "                matrixB_temp[i][j] = 1\n",
    "    matrixB = matrixB_temp.T\n",
    "    return matrixA, matrixB #as this is a zero-sum game, matrixA + matrixB.T = zero matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1:\n",
    "\n",
    "- Initialize 2 strategies for both A and B each.\n",
    "- Generate the payoff matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_strategy(n = 10, size = 3):\n",
    "    #initialise a random strategy\n",
    "    strategy = np.zeros((size,))\n",
    "    strategy[0] = randint(0,10)\n",
    "    strategy[1] = randint(0,10-strategy[0])\n",
    "    strategy[2] = 10 - strategy[0] - strategy[1]\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2., 2., 6.]), array([5., 5., 0.])]\n",
      "[array([1., 5., 4.]), array([2., 6., 2.])]\n",
      "[[ 1.  0.]\n",
      " [ 0. -1.]]\n",
      "[[-1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "A_policies = [initialise_strategy(), initialise_strategy()]\n",
    "B_policies = [initialise_strategy(), initialise_strategy()]\n",
    "matrixA,matrixB = payoff_matrices(A_policies, B_policies)\n",
    "print(A_policies)\n",
    "print(B_policies)\n",
    "print(matrixA)\n",
    "print(matrixB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nash_eq(A)*:\n",
    "- Input: matrix A of a population\n",
    "- Output: Nash equilibrium p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nash_eq(A):\n",
    "    '''Input: matrix A of a population\n",
    "        Output: Nash equilibrium'''\n",
    "    n = A.shape[0]\n",
    "    A_ub = np.concatenate((-A.T,[np.ones(n,),-np.ones(n,)]), axis = 0)\n",
    "    b_ub = np.append(np.zeros((n,)),[1,-1])\n",
    "    soln = linprog(c = np.zeros((n,)), A_ub = A_ub, b_ub = b_ub, bounds = (0,1))\n",
    "    return soln.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPS example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,1,-1],[-1,0,1],[1,-1,0]])\n",
    "print(Nash_eq(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
