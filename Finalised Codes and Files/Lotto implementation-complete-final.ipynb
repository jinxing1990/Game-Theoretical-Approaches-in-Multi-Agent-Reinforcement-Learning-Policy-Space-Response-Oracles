{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Lotto Implementation\n",
    "(based on the \"Open-ended Learning in Symmetric Zero-sum Games\" paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "\n",
    "**Differentiable Lotto** is inspired by continuous Lotto (Hart, S. Discrete Colonel Blotto and General Lotto games. Int J Game Theory, 36:441–460, 2008.). The game is defined over a fixed set $C$ of $c$ 'customers', each being a point in $\\mathbb{R}^2$. An agent’s strategy $(p, v) = \\{(p_1,v_1), ... , (p_k,v_k)\\}$, distributes one unit of mass over $k$ servers, where each server is a point $v_i \\in \\mathbb{R}^2$. Roughly, given the strategies of two players, $(p,v)$, $(q,w)$, customers are softly assigned to the nearest servers, determining the agents’ payoffs.\n",
    "\n",
    "More formally, the payoff is\n",
    "\n",
    "$$\n",
    "\\phi((p,v), (q,w)) := \\sum_{i,j=1}^{c,k} (p_j v_{ij} - q_j w_{ij}),$$\n",
    "\n",
    "where the scalars $v_{ij}$ and $w_{ij}$ depend on the distance between customer $i$ and the servers:\n",
    "\n",
    "$$(v_{i1}, ... , w_{ik}) := softmax(-||c_i - v_1||^2, ... , -||c_i - w_k||^2),$$\n",
    "\n",
    "where $c_i$ is the coordinate of customer $i$.\n",
    "\n",
    "The width of a cloud of points is the expected distance from the barycenter. We impose agents to have width equal one. We use gradient ascent as our oracle.\n",
    "\n",
    "For this implmentation,\n",
    "\n",
    "- $c = 9$ customers chosen uniformly at random in the square $[-1,1]^2$\n",
    "- $k = 2$ servers\n",
    "- $n = 500$ games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code Implementation of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Importing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from scipy.optimize import linprog\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initialization of initial strategies and fixed c customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*random_point(lb = -1, ub = 1, n = 2)*:\n",
    "- Input: Lower bound (lb), upper bound (ub) of each coordinate in $\\mathbb{R}^n$ space\n",
    "- Output: random point within the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point(lb = -9999, ub = 1, n = 2):\n",
    "    point = np.zeros((n,))\n",
    "    for i in range(n):\n",
    "        point[i] = np.random.uniform(lb, ub)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8208.76741583, -6061.49825156])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*random_points_list(lb = -1, ub = 1, n = 2, k = 2)*:\n",
    "- Input: $k$ number of points with lower bound (lb), upper bound (ub) of each coordinate in $\\mathbb{R}^n$ space\n",
    "- Output: list of $k$ random points within the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_points_list(lb = -1, ub = 1, n = 2, k = 9):\n",
    "    points_list = []\n",
    "    for i in range(k):\n",
    "        points_list.append(random_point(lb,ub,n))\n",
    "    points_list = np.asarray(points_list)\n",
    "    return points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_points_list(k=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*prob_dist(k = 2)*:\n",
    "- Input: $k$\n",
    "- Output: $k$ numbers that sum up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_dist(k = 3):\n",
    "    pd = np.random.uniform(0,1,k)\n",
    "    total = np.sum(pd)\n",
    "    pd = pd/total\n",
    "    return pd.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17583223],\n",
       "       [0.55982887],\n",
       "       [0.2643389 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialise_strategy(lb = -1, ub = 1, n = 2, k = 2)*:\n",
    "- Input: $k$ number of points with lower bound (lb), upper bound (ub) of each coordinate in $\\mathbb{R}^n$ space\n",
    "- Output: p_vector (distribution of k points) and v_vector (k points in $\\mathbb{R}^n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_strategy(lb = -1, ub = 1, n = 2, k = 3):\n",
    "    v_vector = random_points_list(lb, ub, n, k)\n",
    "    p_vector = prob_dist(k)\n",
    "    return [p_vector, v_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialise_strategy(lb = -1, ub = 1, n = 2, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take for example: Generate 2 players' strategies: (p,v) and (q,w) with k = 2 servers each. c = 9 Customers in $[-1,1]^2$ space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[p,v] = initialise_strategy(lb = -1, ub = 1, n = 2, k = 2)\n",
    "C = random_points_list(lb=-1, ub=1, n=2, k = 9)\n",
    "print(\"Player's strategies distribution: \" + np.array2string(p) + \" with servers at \" + np.array2string(v) + \".\")\n",
    "print(\"The customers are located at \" + np.array2string(C) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Necessary functions for PSRO algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nash_eq(A)*:\n",
    "- Input: matrix A of a population\n",
    "- Output: Nash equilibrium p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nash_eq(A):\n",
    "    '''Input: matrix A of a population\n",
    "       Output: Nash equilibrium\n",
    "       Note that A need to be antisymmetric for this function to generate the right Nash p'''\n",
    "    n = A.shape[0]\n",
    "    A_ub = -A.T\n",
    "    b_ub = np.zeros((n,))\n",
    "    A_eq = np.ones((1,n))\n",
    "    b_eq = 1\n",
    "    soln = linprog(c = np.zeros((n,)), A_ub = A_ub, b_ub = b_ub, A_eq = A_eq, b_eq = b_eq, bounds = (0,1),method='interior-point')\n",
    "    return soln.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPS example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.33333333 0.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinxi\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_linprog_ip.py:1262: OptimizeWarning: Solving system with option 'sym_pos':True failed. It is normal for this to happen occasionally, especially as the solution is approached. However, if you see this frequently, consider setting option 'sym_pos' to False.\n",
      "  OptimizeWarning)\n",
      "C:\\Users\\jinxi\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_linprog_ip.py:1274: OptimizeWarning: Solving system with option 'sym_pos':False failed. This may happen occasionally, especially as the solution is approached. However, if you see this frequently, your problem may be numerically challenging. If you cannot improve the formulation, consider setting 'lstsq' to True. Consider also setting `presolve` to True, if it is not already.\n",
      "  OptimizeWarning)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,1,-1],[-1,0,1],[1,-1,0]])\n",
    "print(Nash_eq(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eval_matrix_1pop(popn)*:\n",
    "- Input: list of strategies from 1 population of strategies where each strategy = $[p^i,v^i]$\n",
    "- Output: evaluation matrix A (as described in Section 2 of the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_matrix_1pop(popn, C, k, c):\n",
    "    '''Input: 1 population of strategies\n",
    "       Output: evaluation matrix of that population'''\n",
    "    n = len(popn)\n",
    "    matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            p = popn[i][0]\n",
    "            v = popn[i][1]\n",
    "            q = popn[j][0]\n",
    "            w = popn[j][1]\n",
    "            soft_v, soft_w, dist_v, dist_w = softmax_fn(v,w,C,k,c)\n",
    "            matrix[i][j] = payoff(p, soft_v, q, soft_w)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eval_matrix_2pop(popn)*:\n",
    "- Input: lists of strategies from 2 population of strategies where each strategy = $[p^i,v^i]$ (no. of strategies from population A can differ from population B's)\n",
    "- Output: evaluation matrix A (as described in Section 2 of the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_matrix_2pop(popn1,popn2):\n",
    "#     '''Input: 2 population of strategies\n",
    "#        Output: evaluation matrix of those 2 populations'''\n",
    "#     n = len(popn1)\n",
    "#     m = len(popn2)\n",
    "#     matrix = np.zeros((n,m))\n",
    "#     for i in range(n):\n",
    "#         for j in range(m):\n",
    "#             matrix[i][j] = payoff(popn1[i],popn2[j])\n",
    "#     return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_fn(v,w,C,k,c):\n",
    "    dist_v=np.zeros((c,k));\n",
    "    dist_w=np.zeros((c,k));\n",
    "    soft_v=np.zeros((c,k));\n",
    "    soft_w=np.zeros((c,k));\n",
    "    for i in range(c):\n",
    "        for j in range(k):\n",
    "            dist_v[i][j]=np.exp(-np.linalg.norm(C[i,:]-v[j,:])**2)\n",
    "            dist_w[i][j]=np.exp(-np.linalg.norm(C[i,:]-w[j,:])**2)\n",
    "        soft_v[i,:]=dist_v[i,:]/(np.sum(dist_v[i,:])+np.sum(dist_w[i,:]));\n",
    "        soft_w[i,:]=dist_w[i,:]/(np.sum(dist_v[i,:])+np.sum(dist_w[i,:]));\n",
    "    return soft_v,soft_w,dist_v,dist_w     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(strategy):\n",
    "    new_p = strategy[0]\n",
    "    p1 = new_p[0]\n",
    "    p2 = new_p[1]\n",
    "    v1 = strategy[1][0]\n",
    "    v2 = strategy[1][1]\n",
    "    b = p1*v1 + p2*v2\n",
    "    c1 = v1 - b\n",
    "    c2 = v2 - b\n",
    "    final_a1 = 0\n",
    "    final_a2 = 0\n",
    "    a2_1 = (2 -(c1+c2))/(1-p2/p1)\n",
    "    a1_1 = (-p2/p1)*a2_1\n",
    "    a2_2 = -(2 + (c1-c2))/(1+p2/p1)\n",
    "    a1_2 = (-p2/p1)*a2_2\n",
    "    a2_3 = (2+(c2-c1))/(1+p2/p1)\n",
    "    a1_3 = (-p2/p1)*a2_3\n",
    "    a2_4 = (c1+c2-2)/(1-p2/p1)\n",
    "    a1_4 = (-p2/p1)*a2_4\n",
    "    if a1_1 > c1 and a2_1 > c2:\n",
    "        final_a1 = a1_1\n",
    "        final_a2 = a2_1\n",
    "    elif a1_2 > c1 and a2_2 < c2:\n",
    "        final_a1 = a1_2\n",
    "        final_a2 = a2_2\n",
    "    elif a1_3 < c1 and a2_3 > c2:\n",
    "        final_a1 = a1_3\n",
    "        final_a2 = a2_3\n",
    "    else:\n",
    "        final_a1 = a1_4\n",
    "        final_a2 = a2_4\n",
    "    new_v1 = v1 - final_a1\n",
    "    new_v2 = v2 - final_a2\n",
    "    new_v = np.array([new_v1,new_v2])\n",
    "    new_strategy = [new_p, new_v]\n",
    "    return new_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff(p,soft_v,q,soft_w):\n",
    "    payoff=np.sum(np.dot(soft_v,p)-np.dot(soft_w,q))\n",
    "    return payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(popn,nash_p,A,eta,C,k,c):\n",
    "    new_agents = []\n",
    "    for i in range(len(popn)):\n",
    "        if(nash_p[i]>0):\n",
    "            curr_agent_p=popn[-1][0].reshape(k,1);\n",
    "            curr_agent_v=popn[-1][1];\n",
    "            curr_agent_idx=i;\n",
    "            next_agent_p=curr_agent_p+eta*gradient_p(popn,nash_p,A,curr_agent_idx,curr_agent_v,C,k,c);\n",
    "            next_agent_p = next_agent_p/np.sum(next_agent_p)\n",
    "            next_agent_v=curr_agent_v+eta*gradient_v(popn,nash_p,A,curr_agent_idx,curr_agent_p,curr_agent_v,C,k,c);\n",
    "            new_agents.append([next_agent_p,next_agent_v])\n",
    "    #print(gradient_v(popn,nash_p,curr_agent_p,curr_agent_v,C,k,c))\n",
    "    return new_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_p(popn,nash_p,A,curr_agent_idx,agent_v,C,k,c):\n",
    "    sum_vec=np.zeros((k,1));\n",
    "    for i in range(len(popn)):\n",
    "        if (A[curr_agent_idx][i]>=0):\n",
    "            temp_agent_p=popn[i][0].reshape(k,1);\n",
    "            temp_agent_v=popn[i][1];\n",
    "            temp_v,temp_w,tempdist_v,tempdist_w=softmax_fn(agent_v,temp_agent_v,C,k,c);\n",
    "            val_grad=np.sum(temp_v,axis=0).reshape(k,1) #sum the rows\n",
    "            sum_vec=sum_vec+nash_p[i]*val_grad; #multiply w.r.t Nash p.\n",
    "        \n",
    "    return sum_vec; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_v(popn,nash_p,A,curr_agent_idx,agent_p,agent_v,C,k,c): #agent_p, agent_v are strategies of the current agent \"v_t of popn B_t\"\n",
    "    sum_mat=np.zeros((k,3));\n",
    "    for i in range(len(popn)):\n",
    "        if (A[curr_agent_idx][i]>=0):\n",
    "            temp_agent_p=popn[i][0].reshape(k,1);\n",
    "            temp_agent_v=popn[i][1];\n",
    "            temp_v,temp_w,tempdist_v,tempdist_w=softmax_fn(agent_v,temp_agent_v,C,k,c);\n",
    "            val_grad_mat=calc_gradient_matrix(agent_p,agent_v,temp_agent_p,temp_agent_v,temp_v,temp_w,tempdist_v,tempdist_w,C,k,c) #sum the rows\n",
    "        #To add the remaining parameters to calc_gradient_matrix function-See below.\n",
    "            sum_mat=sum_mat+nash_p[i]*val_grad_mat; #multiply w.r.t Nash p.\n",
    "        \n",
    "    return sum_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_matrix(agent_p,agent_v,temp_agent_p,temp_agent_v,temp_v,temp_w,tempdist_v,tempdist_w,C,k,c):\n",
    "    #agent_p - p vector of agent v_t\n",
    "    #temp_agent_q- q vector of the \"current opposition agent\"\n",
    "    #W- location matrix of \"current opposition agent\"\n",
    "    #V- location matrix of agent v_t\n",
    "    grad_mat=np.zeros((k,3));\n",
    "    V=agent_v;\n",
    "    W=temp_agent_v;\n",
    "    for j in range(k):\n",
    "        S_v=0;\n",
    "        S_w=0;\n",
    "        for i in range(c):\n",
    "            for l in range(k):\n",
    "                v_loc=V[j,:];\n",
    "                S_v=S_v+agent_p[j]*grad_payoff(v_loc,j,l,1,i,temp_v,temp_w,tempdist_v,tempdist_w,C,k,c);\n",
    "                S_w=S_w+temp_agent_p[j]*grad_payoff(v_loc,j,l,0,i,temp_v,temp_w,tempdist_v,tempdist_w,C,k,c);\n",
    "        \n",
    "         \n",
    "        grad_mat[j,:]=S_v-S_w;  \n",
    "      \n",
    "    return grad_mat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_payoff(v_loc,v_loc_idx,w_loc_idx,agent_bool,c_idx,temp_v,temp_w,dist_v,dist_w,C,k,c): #Gradient with respect to v_loc a location strategy of agent v.\n",
    "    \n",
    "    if(agent_bool==1): #Differentiating agent_v\n",
    "        \n",
    "        if(v_loc_idx==w_loc_idx):\n",
    "            grad=(2*(C[c_idx,:]-v_loc)*dist_v[c_idx,v_loc_idx]*(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:])-dist_v[c_idx,v_loc_idx]))/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))**2\n",
    "        else:\n",
    "            grad=(-2*(C[c_idx,:]-v_loc)*dist_v[c_idx,v_loc_idx]*dist_v[c_idx,w_loc_idx])/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))**2\n",
    "    \n",
    "    else:\n",
    "#         if(v_loc_idx==w_loc_idx): #Differentiating agent_w\n",
    "#             grad=(2*(C[c_idx,:]-v_loc)*dist_v[c_idx,v_loc_idx]*(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:])-dist_w[c_idx,v_loc_idx]))/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))**2\n",
    "#         else:\n",
    "        grad=(-2*(C[c_idx,:]-v_loc)*dist_v[c_idx,v_loc_idx]*dist_w[c_idx,w_loc_idx])/(np.sum(dist_v[c_idx,:])+np.sum(dist_w[c_idx,:]))**2   \n",
    "    \n",
    "    return grad    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 PSRO$_N$ and Self-play Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSRO_N(popn, C, k, c, eta = 1, epoch = 5):\n",
    "    strategies = popn\n",
    "    n = len(strategies)\n",
    "    for i in range(epoch):\n",
    "        A = eval_matrix_1pop(strategies, C, k, c)\n",
    "        nash_p = Nash_eq(A)\n",
    "        print(nash_p)\n",
    "        new_strategy_set = oracle(strategies,nash_p,A,eta,C,k,c)\n",
    "        strategies.extend(new_strategy_set)\n",
    "        n = n + 1\n",
    "        print(\"There are \" + str(n) + \" strategies in the population now.\")\n",
    "    return strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Self_play(popn, C, k, c, eta = 1, epoch = 5):\n",
    "    strategies =  popn\n",
    "    n = len(strategies)\n",
    "    for i in range(epoch):\n",
    "        nash_p = np.zeros((n,1))\n",
    "        nash_p[-1] = 1\n",
    "        print(nash_p)\n",
    "        new_p, new_v = oracle(strategies,nash_p,eta,C,k,c)\n",
    "        new_strategy = [new_p, new_v]\n",
    "        strategies.append(new_strategy)\n",
    "        n = n + 1\n",
    "        print(\"There are \" + str(n) + \" strategies in the population now.\")\n",
    "    return strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Population Performance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rel_popn_perf(popn1, popn2)*:\n",
    "- Input: lists of strategies from 2 population of strategies where each strategy = $[p^i,v^i]$ (no. of strategies from population A can differ from population B's)\n",
    "- Output: relative population performance (defined in Definition 3 of Section 3.1 in th paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_popn_perf(popn1, popn2):\n",
    "    perf = 0\n",
    "    A_1 = eval_matrix_1pop(popn1)\n",
    "    A_2 = eval_matrix_1pop(popn2)\n",
    "    A_12 = eval_matrix_2pop(popn1,popn2)\n",
    "    p = Nash_eq(A_1).reshape(-1,1)\n",
    "    q = Nash_eq(A_2).reshape(-1,1)\n",
    "    perf = np.dot(np.dot(p.T,A_12),q)\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eff_diversity(popn)*:\n",
    "- Input: list of strategies from 1 population of strategies where each strategy = $[p^i,v^i]$\n",
    "- Output: effective diversity of the population (defined in Definition 4 of Section 3.2 in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_diversity(popn):\n",
    "    d = 0\n",
    "    A = eval_matrix_1pop(popn)\n",
    "    p = Nash_eq(A).reshape(-1,1)\n",
    "    A_plus = np.clip(A,0,None)\n",
    "    d = np.dot(np.dot(p.T,A_plus),p)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running all implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Initialisation of population and customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: DO NOT RUN THE CODE BELOW!!!**\n",
    "--------\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lb = -1 #lower bound of the space\n",
    "ub = 1 #upper bound of the space\n",
    "n = 2 #dimension of the space\n",
    "c = 9 #number of customers\n",
    "\n",
    "strategy1_3s = initialise_strategy(lb, ub, n, k=3) # 1st strategy for 3 servers\n",
    "strategy1_9s = initialise_strategy(lb, ub, n, k=9) # 1st strategy for 9 servers\n",
    "strategy1_15s = initialise_strategy(lb, ub, n, k=15) # 1st strategy for 15 servers\n",
    "\n",
    "popn_3s = [strategy1_3s]\n",
    "popn_9s = [strategy1_9s]\n",
    "popn_15s = [strategy1_15s]\n",
    "\n",
    "C = random_points_list(lb, ub, n, k = c)\n",
    "\n",
    "initialisation = open('initialisation.pkl','wb')\n",
    "pickle.dump(popn_3s, initialisation)\n",
    "pickle.dump(popn_9s, initialisation)\n",
    "pickle.dump(popn_15s, initialisation)\n",
    "pickle.dump(C, initialisation)\n",
    "initialisation.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = -1 #lower bound of the space\n",
    "ub = 1 #upper bound of the space\n",
    "n = 3 #dimension of the space\n",
    "c = 1 #number of customers\n",
    "\n",
    "C = random_points_list(lb, ub, n, k = c)\n",
    "\n",
    "strategy1_3s = initialise_strategy(lb, ub, n, k=3)\n",
    "strategy2_3s = initialise_strategy(lb, ub, n, k=3)\n",
    "strategy3_3s = initialise_strategy(lb, ub, n, k=3)\n",
    "\n",
    "popn = [strategy1_3s, strategy2_3s, strategy3_3s]\n",
    "\n",
    "A = eval_matrix_1pop(popn, C, k=3, c=1)\n",
    "nash = Nash_eq(A)\n",
    "print(A)\n",
    "print(nash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_popn = PSRO_N(popn = popn, C = C, k=3, c = 1, eta = 1,epoch = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JUST RUN THIS TO LOAD THE INITIAL POPULATIONS AND FIXED CUSTOMERS**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = -1 #lower bound of the space\n",
    "ub = 1 #upper bound of the space\n",
    "n = 2 #dimension of the space\n",
    "c = 9 #number of customers\n",
    "\n",
    "initialisation = open('initialisation.pkl', 'rb')\n",
    "popn_3s = pickle.load(initialisation)\n",
    "popn_9s = pickle.load(initialisation)\n",
    "popn_15s = pickle.load(initialisation)\n",
    "C = pickle.load(initialisation)\n",
    "initialisation.close()\n",
    "print(\"1st strategy for 3 servers:\")\n",
    "print(popn_3s)\n",
    "print(\"1st strategy for 9 servers:\")\n",
    "print(popn_9s)\n",
    "print(\"1st strategy for 15 servers:\")\n",
    "print(popn_15s)\n",
    "print(\"The fixed 9 customers are:\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Self-play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: DO NOT RUN THE CODE BELOW!!!**\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = -1 #lower bound of the space\n",
    "ub = 1 #upper bound of the space\n",
    "n = 2 #dimension of the space\n",
    "c = 9 #number of customers\n",
    "\n",
    "initialisation = open('initialisation.pkl', 'rb')\n",
    "popn_3s = pickle.load(initialisation)\n",
    "popn_9s = pickle.load(initialisation)\n",
    "popn_15s = pickle.load(initialisation)\n",
    "C = pickle.load(initialisation)\n",
    "initialisation.close()\n",
    "print(\"1st strategy for 3 servers:\")\n",
    "print(popn_3s)\n",
    "print(\"1st strategy for 9 servers:\")\n",
    "print(popn_9s)\n",
    "print(\"1st strategy for 15 servers:\")\n",
    "print(popn_15s)\n",
    "print(\"The fixed 9 customers are:\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_self_play = open('popn_self_play.pkl','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popn_self_play_3s = Self_play(popn = popn_3s, C = C, k=3, c = 9, eta = 1,epoch = 100)\n",
    "pickle.dump(popn_self_play_3s, popn_self_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_self_play_9s = Self_play(popn = popn_9s, C = C, k=9, c = 9, eta = 1,epoch = 100)\n",
    "pickle.dump(popn_self_play_9s, popn_self_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_self_play_15s = Self_play(popn = popn_15s, C = C, k=15, c = 9, eta = 1,epoch = 100)\n",
    "pickle.dump(popn_self_play_15s, popn_self_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popn_self_play.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JUST RUN THIS TO LOAD THE STRATEGIES OF ALL SELF-PLAY POPULATIONS**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_self_play = open('popn_self_play.pkl', 'rb')\n",
    "popn_self_play_3s = pickle.load(popn_self_play)\n",
    "popn_self_play_9s = pickle.load(popn_self_play)\n",
    "popn_self_play_15s = pickle.load(popn_self_play)\n",
    "popn_self_play.close()\n",
    "print(len(popn_self_play_3s), len(popn_self_play_9s), len(popn_self_play_15s))\n",
    "print(\"Last strategy for 3 servers:\")\n",
    "print(popn_self_play_3s[-1])\n",
    "print(\"Last strategy for 9 servers:\")\n",
    "print(popn_self_play_9s[-1])\n",
    "print(\"Last strategy for 15 servers:\")\n",
    "print(popn_self_play_15s[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots how the phi value change as a new strategy is trained for 100 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_changes_3s = []\n",
    "for i in range(len(popn_self_play_3s)-1):\n",
    "    soft_v, soft_w, _, _ = softmax_fn(popn_self_play_3s[i+1][1],popn_self_play_3s[i][1],C,k=3,c=9)\n",
    "    phi = payoff(popn_self_play_3s[i+1][0],soft_v,popn_self_play_3s[i][0],soft_w) \n",
    "    phi_changes_3s.append(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(range(len(phi_changes_3s)), phi_changes_3s)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Phi Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 PSRO$_N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: DO NOT RUN THE CODE BELOW!!!**\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = -1 #lower bound of the space\n",
    "ub = 1 #upper bound of the space\n",
    "n = 2 #dimension of the space\n",
    "c = 9 #number of customers\n",
    "\n",
    "initialisation = open('initialisation.pkl', 'rb')\n",
    "popn_3s = pickle.load(initialisation)\n",
    "popn_9s = pickle.load(initialisation)\n",
    "popn_15s = pickle.load(initialisation)\n",
    "C = pickle.load(initialisation)\n",
    "initialisation.close()\n",
    "print(\"1st strategy for 3 servers:\")\n",
    "print(popn_3s)\n",
    "print(\"1st strategy for 9 servers:\")\n",
    "print(popn_9s)\n",
    "print(\"1st strategy for 15 servers:\")\n",
    "print(popn_15s)\n",
    "print(\"The fixed 9 customers are:\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_psro_n = open('popn_psro_n.pkl','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_psro_n_3s = PSRO_N(popn = popn_3s, C = C, k=3, c = 50, eta = 1,epoch = 5)\n",
    "#pickle.dump(popn_psro_n_3s, popn_psro_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popn_psro_n_3s[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_psro_n_9s = PSRO_N(popn = popn_9s, C = C, k=9, c = 9, eta = 1,epoch = 100)\n",
    "pickle.dump(popn_psro_n_9s, popn_psro_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_psro_n_15s = PSRO_N(popn = popn_15s, C = C, k=15, c = 9, eta = 1,epoch = 100)\n",
    "pickle.dump(popn_psro_n_15s, popn_psro_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popn_psro_n.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JUST RUN THIS TO LOAD THE STRATEGIES OF ALL PSRO$_N$ POPULATIONS**\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = -1 #lower bound of the space\n",
    "ub = 1 #upper bound of the space\n",
    "n = 2 #dimension of the space\n",
    "c = 9 #number of customers\n",
    "\n",
    "initialisation = open('initialisation.pkl', 'rb')\n",
    "popn_3s = pickle.load(initialisation)\n",
    "popn_9s = pickle.load(initialisation)\n",
    "popn_15s = pickle.load(initialisation)\n",
    "C = pickle.load(initialisation)\n",
    "initialisation.close()\n",
    "print(\"1st strategy for 3 servers:\")\n",
    "print(popn_3s)\n",
    "print(\"1st strategy for 9 servers:\")\n",
    "print(popn_9s)\n",
    "print(\"1st strategy for 15 servers:\")\n",
    "print(popn_15s)\n",
    "print(\"The fixed 9 customers are:\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popn_psro_n = open('popn_psro_n.pkl', 'rb')\n",
    "popn_psro_n_3s = pickle.load(popn_psro_n)\n",
    "popn_psro_n_9s = pickle.load(popn_psro_n)\n",
    "popn_psro_n_15s = pickle.load(popn_psro_n)\n",
    "popn_psro_n.close()\n",
    "print(len(popn_psro_n_3s), len(popn_psro_n_9s), len(popn_psro_n_15s))\n",
    "print(\"Last strategy for 3 servers:\")\n",
    "print(popn_psro_n_3s[-1])\n",
    "print(\"Last strategy for 9 servers:\")\n",
    "print(popn_psro_n_9s[-1])\n",
    "print(\"Last strategy for 15 servers:\")\n",
    "print(popn_psro_n_15s[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "for i in range(15):\n",
    "    x.append(popn_psro_n_15s[100][-1][i][0])\n",
    "\n",
    "y = []\n",
    "for i in range(15):\n",
    "    y.append(popn_psro_n_15s[100][-1][i][1])\n",
    "    \n",
    "x_c = []\n",
    "for i in range(len(C)):\n",
    "    x_c.append(C[i][0])\n",
    "\n",
    "y_c = []\n",
    "for i in range(len(C)):\n",
    "    y_c.append(C[i][1])\n",
    "\n",
    "plt.scatter(x_center,y_center,c='m')\n",
    "plt.scatter(x,y)\n",
    "#plt.scatter(x_f,y_f,c='g')\n",
    "plt.scatter(x_c,y_c,c='r')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15294082961335842 0.02049134720967833\n"
     ]
    }
   ],
   "source": [
    "x_center = sum(x_c)/9\n",
    "y_center = sum(y_c)/9\n",
    "\n",
    "print(x_center,y_center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
